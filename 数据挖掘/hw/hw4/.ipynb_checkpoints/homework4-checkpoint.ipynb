{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "Student id: 杨筠松 U202115980 电信提高2101班\n",
    "\n",
    "8.1 Briefly outline the major steps of decision tree classification \n",
    "\n",
    "- 初始化根节点：决策树从包含所有训练元组的单一根节点开始。\n",
    "- 检查节点元组的类别：如果节点中的所有元组都属于同一个类，则该节点变成一个叶子节点，并用该类标记。\n",
    "- 选择属性进行分裂：如果元组属于不同的类，就调用一个属性选择方法来确定分裂标准。这个方法可能使用启发式或统计度量，比如信息增益、增益比或基尼指数，以选择“最佳”的方式将元组按属性值分成不同的类别。分裂属性的选择可能还会指出一个分裂点或分裂子集。\n",
    "- 节点标记与分支生长：节点被标记为分裂标准，这个标准在节点上进行测试。根据分裂标准的不同结果，从节点生长出分支，并且相应地对元组进行分区。分区有三种可能的情况：如果分裂属性是离散值，为每个可能的属性值生长出一个分支；如果是连续值，生长两个分支，对应于条件“属性A <= 分裂点”和“属性A > 分裂点”；如果分裂属性是离散的且需要产生一个二叉树，那么节点的测试是“属性A是否在子集SA中”。\n",
    "递归构建：算法递归地为每个分区创建决策树。\n",
    "\n",
    "**停止条件**：\n",
    "\n",
    "- 如果一个节点上的所有元组都属于同一类，将该节点变为一个叶子节点。\n",
    "- 如果没有更多的属性来进行分区，则通过多数投票转换当前节点为叶子节点，标记为元组中最常见的类。\n",
    "- 如果一个分支上没有元组，则从父节点继承多数类来创建一个叶子节点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.3 Given a decision tree, you have the option of (a) converting the decision tree to rules and then pruning the resulting rules, or (b) pruning the decision tree and then converting the pruned tree to rules. What advantage does (a) have over (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑对子树进行剪枝，那么如果采用方法(b),那么将完全移除这个子树。但是如果使用(a)方式进行对规则的剪枝，那么我们可能会移除它的任何前提条件，这种方式的限制性更小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.6 Why is na¨ıve Bayesian classification called “na¨ıve”? Briefly outline the major ideas of na¨ıve Bayesian\n",
    "classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "朴素贝叶斯分类之所以被称为“朴素”，是因为它假设各个特征之间相互独立，这是一个非常朴素的假设，在现实中往往不成立。但即便如此，朴素贝叶斯分类器因其简单性和效率而广泛应用。\n",
    "\n",
    "朴素贝叶斯分类的主要思想是：它基于贝叶斯定理来预测给定输入数据所属类别的概率。分类时，对于一个未知类别的样本，朴素贝叶斯分类器会计算样本属于各个类别的概率，并将样本分类到概率最高的类别。这个过程包括利用训练数据来估计概率模型参数，然后应用这些参数来对新数据进行分类。尽管其独立性假设很“朴素”，但在许多实际情况下，朴素贝叶斯分类器表现得出奇地好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.1 The following table consists of training data from an employee database. The data have been generalized. For example, “31 . . . 35” for age represents the age range of 31 to 35. For a given row entry, count represents the number of data tuples having the values for department, status, age, and salary \n",
    "given in that row.\n",
    "\n",
    "![](./imgs/data.png)\n",
    "\n",
    "Let status be the class label attribute.\n",
    "(a) Design a multilayer feed-forward neural network for the given data. Label the nodes in the input\n",
    "and output layers.\n",
    "(b) Using the multilayer feed-forward neural network obtained above, show the weight values after one\n",
    "iteration of the backpropagation algorithm, given the training instance “(sales, senior, 31. . . 35,\n",
    "46K. . . 50K)”. Indicate your initial weight values and biases, and the learning rate used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以设计得到如下的图形\n",
    "![](./imgs/layers.jpg)\n",
    "并且设置初始化权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_to_hidden': array([[ 0.04967142, -0.01382643,  0.06476885,  0.15230299],\n",
       "        [-0.02341534, -0.0234137 ,  0.15792128,  0.07674347],\n",
       "        [-0.04694744,  0.054256  , -0.04634177, -0.04657298],\n",
       "        [ 0.02419623, -0.19132802, -0.17249178, -0.05622875],\n",
       "        [-0.10128311,  0.03142473, -0.09080241, -0.14123037],\n",
       "        [ 0.14656488, -0.02257763,  0.00675282, -0.14247482]]),\n",
       " 'hidden_to_output': array([[-0.05443827],\n",
       "        [ 0.01109226],\n",
       "        [-0.11509936],\n",
       "        [ 0.0375698 ]]),\n",
       " 'biases_hidden': array([-0.06006387, -0.02916937, -0.06017066,  0.18522782]),\n",
       " 'biases_output': array([-0.00134972])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 设定一个随机数种子以获得可重复的结果\n",
    "np.random.seed(42)\n",
    "\n",
    "# 设计一个神经网络结构\n",
    "input_nodes = 6\n",
    "hidden_nodes = 4\n",
    "output_nodes = 1\n",
    "\n",
    "# 初始化权重和偏置\n",
    "weights_input_to_hidden = np.random.normal(0.0, scale=0.1, size=(input_nodes, hidden_nodes))\n",
    "weights_hidden_to_output = np.random.normal(0.0, scale=0.1, size=(hidden_nodes, output_nodes))\n",
    "biases_hidden = np.random.normal(0.0, scale=0.1, size=(hidden_nodes,))\n",
    "biases_output = np.random.normal(0.0, scale=0.1, size=(output_nodes,))\n",
    "\n",
    "# 设定学习率\n",
    "learning_rate = 0.1\n",
    "\n",
    "# 打印初始权重和偏置\n",
    "initial_weights = {\n",
    "    'input_to_hidden': weights_input_to_hidden,\n",
    "    'hidden_to_output': weights_hidden_to_output,\n",
    "    'biases_hidden': biases_hidden,\n",
    "    'biases_output': biases_output\n",
    "}\n",
    "\n",
    "initial_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用一个训练实例来进行一次前向传播和反向传播的迭代来更新权重。训练实例为“sales, senior, 31...35, 46K...50K”，并且我们使用区间的中点来代表这些值,将“sales”转换为独热编码，并设“senior”状态为类标签 1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_to_hidden': array([[ 0.04965467, -0.01379089,  0.06467914,  0.15230299],\n",
       "        [-0.02341534, -0.0234137 ,  0.15792128,  0.07674347],\n",
       "        [-0.04694744,  0.054256  , -0.04634177, -0.04657298],\n",
       "        [ 0.02419623, -0.19132802, -0.17249178, -0.05622875],\n",
       "        [-0.10183554,  0.0325977 , -0.09376312, -0.14123014],\n",
       "        [ 0.14576134, -0.0208715 ,  0.00244633, -0.14247449]]),\n",
       " 'hidden_to_output': array([[-0.04191001],\n",
       "        [ 0.01722617],\n",
       "        [-0.11426577],\n",
       "        [ 0.03756998]]),\n",
       " 'biases_hidden': array([-0.06008061, -0.02913383, -0.06026038,  0.18522783]),\n",
       " 'biases_output': array([0.01149379])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义激活函数，这里我们使用 Sigmoid 函数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# 定义 Sigmoid 函数的导数，用于反向传播\n",
    "def sigmoid_prime(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# 训练实例的输入和目标输出\n",
    "# 独热编码 \"sales\" 为 [1, 0, 0, 0], 年龄 \"31...35\" 使用中点 33, 薪水 \"46K...50K\" 使用中点 48K\n",
    "# 我们将薪水简单归一化为 48，只是为了简化示例\n",
    "input_values = np.array([1, 0, 0, 0, 33, 48])\n",
    "target_output = np.array([1])\n",
    "\n",
    "# 前向传播\n",
    "hidden_layer_input = np.dot(input_values, weights_input_to_hidden) + biases_hidden\n",
    "hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "output_layer_input = np.dot(hidden_layer_output, weights_hidden_to_output) + biases_output\n",
    "output = sigmoid(output_layer_input)\n",
    "\n",
    "# 计算误差\n",
    "error = target_output - output\n",
    "\n",
    "# 反向传播\n",
    "output_error_term = error * sigmoid_prime(output)\n",
    "hidden_error_term = np.dot(output_error_term, weights_hidden_to_output.T) * sigmoid_prime(hidden_layer_output)\n",
    "\n",
    "# 更新隐藏层到输出层的权重\n",
    "delta_weights_hidden_to_output = learning_rate * output_error_term * hidden_layer_output[:, None]\n",
    "weights_hidden_to_output += delta_weights_hidden_to_output\n",
    "\n",
    "# 更新输入层到隐藏层的权重\n",
    "delta_weights_input_to_hidden = learning_rate * hidden_error_term * input_values[:, None]\n",
    "weights_input_to_hidden += delta_weights_input_to_hidden\n",
    "\n",
    "# 更新偏置项\n",
    "biases_hidden += learning_rate * hidden_error_term\n",
    "biases_output += learning_rate * output_error_term\n",
    "\n",
    "# 打印更新后的权重和偏置\n",
    "updated_weights = {\n",
    "    'input_to_hidden': weights_input_to_hidden,\n",
    "    'hidden_to_output': weights_hidden_to_output,\n",
    "    'biases_hidden': biases_hidden,\n",
    "    'biases_output': biases_output\n",
    "}\n",
    "\n",
    "updated_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.5 Write an algorithm for k-nearest neighbor classification given k, the nearest number of neighbors, and n, the number of attributes describing each tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbors(data, query, k, distance_fn, choice_fn):\n",
    "    neighbor_distances_and_indices = []\n",
    "    \n",
    "    # 对于每一个已知类别的点\n",
    "    for index, example in enumerate(data):\n",
    "        # 计算它与待查询点之间的距离\n",
    "        distance = distance_fn(example[:-1], query)\n",
    "        \n",
    "        # 将距离和索引添加到一个集合中\n",
    "        neighbor_distances_and_indices.append((distance, index))\n",
    "    \n",
    "    # 根据距离排序找到最近的k个邻居\n",
    "    sorted_neighbor_distances_and_indices = sorted(neighbor_distances_and_indices)\n",
    "    \n",
    "    # 选择k个最近的邻居\n",
    "    k_nearest_distances_and_indices = sorted_neighbor_distances_and_indices[:k]\n",
    "    \n",
    "    # 使用选择函数决定查询点的类别（例如，通过多数投票）\n",
    "    k_nearest_labels = [data[i][-1] for distance, i in k_nearest_distances_and_indices]\n",
    "    \n",
    "    return k_nearest_distances_and_indices, choice_fn(k_nearest_labels)\n",
    "\n",
    "# 示例距离函数，这里使用欧几里得距离\n",
    "def euclidean_distance(point1, point2):\n",
    "    sum_squared_distance = 0\n",
    "    for i in range(len(point1)):\n",
    "        sum_squared_distance += math.pow(point1[i] - point2[i], 2)\n",
    "    return math.sqrt(sum_squared_distance)\n",
    "\n",
    "# 选择函数，这里使用多数投票\n",
    "def majority_vote(labels):\n",
    "    vote_counts = Counter(labels)\n",
    "    winner, winner_count = vote_counts.most_common(1)[0]\n",
    "    num_winners = len([count for count in vote_counts.values() if count == winner_count])\n",
    "    if num_winners == 1:\n",
    "        # 只有一个赢家，返回它的类别\n",
    "        return winner\n",
    "    else:\n",
    "        # 有多个类别具有相同的票数，可以随机选择一个或者用其他规则决定\n",
    "        return random.choice(labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
